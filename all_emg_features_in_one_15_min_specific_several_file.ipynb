{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57328bb5-42ad-413e-9aa8-28e7db7c8f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import welch\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43b77951-9b6c-4342-9b0a-e8a5fddf2561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore specific FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", message=\"`rcond` parameter will change\")\n",
    "\n",
    "def extract_fetal_emg_features(emg_signal, fs, new_filename, window_len, overlap=0):\n",
    "    # Rectify the EMG signal\n",
    "    rectified_emg = np.abs(emg_signal)\n",
    "\n",
    "    # Extract amplitude features\n",
    "    features = {\n",
    "        'time': new_filename,\n",
    "        'amplitude_mean': np.mean(rectified_emg),\n",
    "        'amplitude_median': np.median(rectified_emg),\n",
    "        'amplitude_rms': np.sqrt(np.mean(rectified_emg**2)),\n",
    "        'amplitude_std': np.std(rectified_emg),\n",
    "        'amplitude_max': np.max(rectified_emg)\n",
    "    }\n",
    "\n",
    "    # Estimate the PSD using Welch's method\n",
    "    freqs, psd = welch(rectified_emg, fs, nperseg=window_len, noverlap=overlap)\n",
    "\n",
    "    # Extract frequency band powers\n",
    "    features['low_power'] = np.trapz(psd[(freqs >= 25) & (freqs <= 60)], freqs[(freqs >= 25) & (freqs <= 60)])\n",
    "    features['med_power'] = np.trapz(psd[(freqs >= 60) & (freqs <= 250)], freqs[(freqs >= 60) & (freqs <= 250)])\n",
    "    features['high_power'] = np.trapz(psd[(freqs >= 250) & (freqs <= 500)], freqs[(freqs >= 250) & (freqs <= 500)])\n",
    "\n",
    "    # Calculate relative powers\n",
    "    total_power = np.trapz(psd, freqs)\n",
    "    features['low_rel_power'] = features['low_power'] / total_power\n",
    "    features['mid_rel_power'] = features['med_power'] / total_power\n",
    "    features['high_rel_power'] = features['high_power'] / total_power\n",
    "\n",
    "    # Extract dominant frequency\n",
    "    frequencies = np.fft.fft(emg_signal)\n",
    "    frequency_range = np.fft.fftfreq(len(emg_signal), 1 / fs)\n",
    "    dominant_frequency_index = np.argmax(np.abs(frequencies[:len(emg_signal) // 2 + 1]))\n",
    "    features['dominant_frequency'] = np.abs(frequency_range[dominant_frequency_index])\n",
    "\n",
    "    # Extract timing features\n",
    "    threshold = 0.1 * np.max(rectified_emg)\n",
    "    onset_times, offset_times = find_emg_onset_offset(rectified_emg, threshold, fs)\n",
    "    features['duration'] = np.median(np.diff(offset_times))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "433eca26-300e-49ed-a985-1fa1802fee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_emg_onset_offset(emg_signal, threshold, fs):\n",
    "    # Find onset times\n",
    "    above_threshold = emg_signal > threshold\n",
    "    diff_above_threshold = np.diff(above_threshold.astype(int))\n",
    "    onset_times = np.where(diff_above_threshold > 0)[0] + 1\n",
    "\n",
    "    # Find offset times\n",
    "    offset_times = np.where(diff_above_threshold < 0)[0] + 1\n",
    "\n",
    "    # Remove offset times before the first onset time\n",
    "    offset_times = offset_times[offset_times >= onset_times[0]]\n",
    "\n",
    "    # If there are more onset times than offset times, remove the last onset time\n",
    "    if len(onset_times) > len(offset_times):\n",
    "        onset_times = onset_times[:-1]\n",
    "\n",
    "    # Convert onset and offset times from samples to seconds\n",
    "    onset_times = onset_times / fs\n",
    "    offset_times = offset_times / fs\n",
    "\n",
    "    return onset_times, offset_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462a6222-bd9d-40b0-acc2-b70c09f0b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_uco_windows_emg(emg_data, fs, start_time, uco_start_time, uco_end_time, additional_file_before=None, additional_start_time_before=None, additional_file_after=None, additional_start_time_after=None, window_len_sec=15):\n",
    "    \"\"\"\n",
    "    Capture UCO time before and after windows and compute EMG features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    emg_data : array-like\n",
    "        The EMG signal data.\n",
    "    fs : int\n",
    "        Sampling frequency of the EMG data.\n",
    "    start_time : str\n",
    "        Start time of the EMG data in format 'HH:MM:SS:%f %p'.\n",
    "    uco_start_time : str\n",
    "        UCO start time in format 'HH:MM:SS.%f %p'.\n",
    "    uco_end_time : str\n",
    "        UCO end time in format 'HH:MM:SS.%f %p'.\n",
    "    additional_file_before : str, optional\n",
    "        Path to the additional file needed for segments before UCO start time.\n",
    "    additional_start_time_before : str, optional\n",
    "        Start time of the additional file for segments before UCO start time.\n",
    "    additional_file_after : str, optional\n",
    "        Path to the additional file needed for segments after UCO end time.\n",
    "    additional_start_time_after : str, optional\n",
    "        Start time of the additional file for segments after UCO end time.\n",
    "    window_len_sec : int\n",
    "        Length of each window in seconds.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : DataFrame\n",
    "        DataFrame containing computed features for each window.\n",
    "    \"\"\"\n",
    "    # Convert times to datetime objects\n",
    "    start_datetime = datetime.strptime(start_time, '%I:%M:%S:%f %p')\n",
    "    uco_start_datetime = datetime.strptime(uco_start_time, '%I:%M:%S.%f %p')\n",
    "    uco_end_datetime = datetime.strptime(uco_end_time, '%I:%M:%S.%f %p')\n",
    "\n",
    "    # Adjust for UCO times that cross midnight\n",
    "    if uco_start_datetime < start_datetime:\n",
    "        uco_start_datetime += timedelta(days=1)\n",
    "    if uco_end_datetime < uco_start_datetime:\n",
    "        uco_end_datetime += timedelta(days=1)\n",
    "    \n",
    "    # Calculate the difference in seconds between the start time and UCO times\n",
    "    time_diff_start = (uco_start_datetime - start_datetime).total_seconds()\n",
    "    time_diff_end = (uco_end_datetime - start_datetime).total_seconds()\n",
    "    \n",
    "    # Convert the time differences to sample indices\n",
    "    uco_start_samples = int(time_diff_start * fs)\n",
    "    uco_end_samples = int(time_diff_end * fs)\n",
    "    \n",
    "    # Define window length in samples\n",
    "    window_len = window_len_sec * fs\n",
    "    \n",
    "    # Calculate the start and end sample indices for the desired windows\n",
    "    start_sample_before = max(0, uco_start_samples - 75 * 60 * fs)\n",
    "    end_sample_before = uco_start_samples - 60 * 60 * fs\n",
    "    start_sample_uco = uco_start_samples\n",
    "    end_sample_uco = uco_end_samples\n",
    "    start_sample_after = uco_end_samples\n",
    "    end_sample_after = min(len(emg_data), uco_end_samples + 60 * window_len)\n",
    "\n",
    "    print(f\"time diff start: {time_diff_start}\")\n",
    "    print(f\"time diff end: {time_diff_end}\")\n",
    "    print(f\"start sample before UCO: {start_sample_before}\")\n",
    "    print(f\"end sample before UCO: {end_sample_before}\")\n",
    "    print(f\"start sample after UCO: {start_sample_after}\")\n",
    "    print(f\"end sample after UCO: {end_sample_after}\")\n",
    "\n",
    "    data = {\n",
    "        'time': [],\n",
    "        'amplitude_mean': [],\n",
    "        'amplitude_median': [],\n",
    "        'amplitude_rms': [],\n",
    "        'amplitude_std': [],\n",
    "        'amplitude_max': [],\n",
    "        'low_power': [],\n",
    "        'med_power': [],\n",
    "        'high_power': [],\n",
    "        'low_rel_power': [],\n",
    "        'mid_rel_power': [],\n",
    "        'high_rel_power': [],\n",
    "        'dominant_frequency': [],\n",
    "        'duration': [],\n",
    "        'label': []\n",
    "    }\n",
    "\n",
    "    def process_windows(signal_data, start_sample, end_sample, label):\n",
    "        for start in range(start_sample, end_sample, window_len):\n",
    "            end = start + window_len\n",
    "            if end > len(signal_data):\n",
    "                break  # Ensure the last window doesn't exceed the data length\n",
    "\n",
    "            segment = signal_data[start:end].flatten()\n",
    "\n",
    "            try:\n",
    "                features = extract_fetal_emg_features(segment, fs, start / fs, window_len, 0)\n",
    "\n",
    "                data['time'].append(start / fs)\n",
    "                data['amplitude_mean'].append(features['amplitude_mean'])\n",
    "                data['amplitude_median'].append(features['amplitude_median'])\n",
    "                data['amplitude_rms'].append(features['amplitude_rms'])\n",
    "                data['amplitude_std'].append(features['amplitude_std'])\n",
    "                data['amplitude_max'].append(features['amplitude_max'])\n",
    "                data['low_power'].append(features['low_power'])\n",
    "                data['med_power'].append(features['med_power'])\n",
    "                data['high_power'].append(features['high_power'])\n",
    "                data['low_rel_power'].append(features['low_rel_power'])\n",
    "                data['mid_rel_power'].append(features['mid_rel_power'])\n",
    "                data['high_rel_power'].append(features['high_rel_power'])\n",
    "                data['dominant_frequency'].append(features['dominant_frequency'])\n",
    "                data['duration'].append(features['duration'])\n",
    "                data['label'].append(label)\n",
    "\n",
    "                plt.close()\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing segment: {e}\")\n",
    "\n",
    "    # Process windows 1 hour and 15 minutes to 1 hour before UCO start time and label as -1\n",
    "    if start_sample_before < end_sample_before:\n",
    "        process_windows(emg_data, start_sample_before, end_sample_before, label=-1)\n",
    "    elif additional_file_before and additional_start_time_before:\n",
    "        additional_data = loadmat(additional_file_before)['save_data'].flatten()\n",
    "        new_start_datetime_before = datetime.strptime(additional_start_time_before, '%I:%M:%S:%f %p')\n",
    "        \n",
    "        # Adjust for additional start time crossing midnight\n",
    "        if uco_start_datetime < new_start_datetime_before:\n",
    "            uco_start_datetime += timedelta(days=1)\n",
    "        \n",
    "        additional_time_diff_start = (uco_start_datetime - new_start_datetime_before).total_seconds() - 75 * 60\n",
    "        additional_start_samples = int(additional_time_diff_start * fs)\n",
    "        process_windows(additional_data, additional_start_samples, additional_start_samples + 60 * window_len, label=-1)\n",
    "    \n",
    "    # Process windows during UCO and label as 0\n",
    "    process_windows(emg_data, start_sample_uco, end_sample_uco, label=0)\n",
    "    \n",
    "    # Process windows after UCO end time and label as 1\n",
    "    remaining_duration = len(emg_data) - start_sample_after\n",
    "    if remaining_duration >= 15 * 60 * fs:\n",
    "        process_windows(emg_data, start_sample_after, end_sample_after, label=1)\n",
    "    else:\n",
    "        process_windows(emg_data, start_sample_after, len(emg_data), label=1)\n",
    "        if additional_file_after and additional_start_time_after:\n",
    "            additional_data = loadmat(additional_file_after)['save_data'].flatten()\n",
    "            new_start_datetime_after = datetime.strptime(additional_start_time_after, '%I:%M:%S:%f %p')\n",
    "            \n",
    "            # Adjust for additional start time crossing midnight\n",
    "            if new_start_datetime_after < start_datetime:\n",
    "                new_start_datetime_after += timedelta(days=1)\n",
    "            \n",
    "            additional_start_samples = 0  # Start from the beginning of the additional file\n",
    "            additional_end_samples = int((15 * 60 * fs - remaining_duration))\n",
    "            process_windows(additional_data, additional_start_samples, additional_end_samples, label=1)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c1de9cc-5a17-4e31-8777-4ea69410e050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time diff start: 1757.855758\n",
      "time diff end: 2655.355758\n",
      "start sample before UCO: 0\n",
      "end sample before UCO: -3684289\n",
      "start sample after UCO: 5310711\n",
      "end sample after UCO: 7110711\n",
      "Processing completed! All processed files have been saved.\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters\n",
    "main_file = r'D:\\IEEE Sensor\\IEEE Sensor Matlab Data\\EMG\\21044\\Clean Data EMGCUsersvaishDownloadsFetal EEG-20231204T232927Z-001Fetal EEGFYP 2023CODE BACK UPRaw Data2104421044_1-06-2021 9_25_16.2 AM_ UCO file Channel 2.mat'\n",
    "handled_folder_path = r'D:\\IEEE Sensor\\IEEE Sensor Xlsx Data\\EMG_handled'\n",
    "fs = 2000  # Sampling frequency\n",
    "start_time = '09:25:16:2 AM'  # Start time of the data\n",
    "uco_start_time = '09:54:34.055758 AM'  # UCO start time\n",
    "uco_end_time = '10:09:31.555758 AM'  # UCO end time\n",
    "\n",
    "additional_file_before = r'D:\\IEEE Sensor\\IEEE Sensor Matlab Data\\EMG\\21044\\Clean Data EMGCUsersvaishDownloadsFetal EEG-20231204T232927Z-001Fetal EEGFYP 2023CODE BACK UPRaw Data2104421044_1-06-2021 9_25_16.2 AM_ UCO file Channel 1.mat'  # Path to additional file for before UCO\n",
    "additional_start_time_before = '11:52:09:0 PM'  # Start time of the additional file for before UCO\n",
    "additional_file_after = r'D:\\IEEE Sensor\\IEEE Sensor Matlab Data\\EMG\\21126\\Clean Data EMGCUsersvaishDownloadsFetal EEG-20231204T232927Z-001Fetal EEGFYP 2023CODE BACK UPRaw Data2112621126_20-08-2021 9_05_07.3 AM Channel 1.mat'  # Path to additional file for after UCO\n",
    "additional_start_time_after = '09:05:07:3 AM'  # Start time of the additional file for after UCO\n",
    "\n",
    "# Make sure the processed folder exists\n",
    "if not os.path.exists(handled_folder_path):\n",
    "    os.makedirs(handled_folder_path)\n",
    "\n",
    "# Load the main file\n",
    "main_data = loadmat(main_file)\n",
    "emg_data = main_data['save_data'].flatten()\n",
    "\n",
    "# Capture UCO windows and compute features\n",
    "df = capture_uco_windows_emg(emg_data, fs, start_time, uco_start_time, uco_end_time, additional_file_before, additional_start_time_before, additional_file_after, additional_start_time_after)\n",
    "\n",
    "# Define new save path\n",
    "folder_name = os.path.basename(os.path.dirname(main_file))\n",
    "new_save_folder = os.path.join(handled_folder_path, folder_name + '_handled')\n",
    "if not os.path.exists(new_save_folder):\n",
    "    os.makedirs(new_save_folder)\n",
    "\n",
    "excel_file_name = os.path.basename(main_file)[:-4] + '.xlsx'  # Change the extension to .xlsx\n",
    "new_excel_file_path = os.path.join(new_save_folder, excel_file_name)\n",
    "\n",
    "df.to_excel(new_excel_file_path, index=False)\n",
    "\n",
    "print(\"Processing completed! All processed files have been saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
