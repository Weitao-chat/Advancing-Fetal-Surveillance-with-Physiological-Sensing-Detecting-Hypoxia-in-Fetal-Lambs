{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3150078-654e-4ca9-b6c1-d546029c8ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import zscore\n",
    "from datetime import datetime, timedelta\n",
    "import neurokit2 as nk\n",
    "from scipy.signal import welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a9a068-34dd-4e08-8ab3-ecb3379d8ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timedomain(rr):\n",
    "    \"\"\"Calculate time domain HRV metrics from RR intervals.\"\"\"\n",
    "    results = {}\n",
    "    if len(rr) == 0:\n",
    "        # If rr is empty, return NaNs or some default values\n",
    "        results['Mean RR (ms)'] = np.nan\n",
    "        results['STD RR/SDNN (ms)'] = np.nan\n",
    "        results['RMSSD (ms)'] = np.nan\n",
    "        results['Mean HR (Kubios\\' style) (beats/min)'] = np.nan\n",
    "        results['Mean HR (beats/min)'] = np.nan\n",
    "        results['STD HR (beats/min)'] = np.nan\n",
    "        results['Min HR (beats/min)'] = np.nan\n",
    "        results['Max HR (beats/min)'] = np.nan\n",
    "        # results['NN50'] = np.nan\n",
    "        # results['pNN50 (%)'] = np.nan\n",
    "    else:\n",
    "        hr = 60 / rr\n",
    "        results['Mean RR (ms)'] = np.mean(rr)\n",
    "        results['STD RR/SDNN (ms)'] = np.std(rr)\n",
    "        results['RMSSD (ms)'] = np.sqrt(np.mean(np.square(np.diff(rr))))\n",
    "        results['Mean HR (Kubios\\' style) (beats/min)'] = 60000 / np.mean(rr)\n",
    "        results['Mean HR (beats/min)'] = np.mean(hr)\n",
    "        results['STD HR (beats/min)'] = np.std(hr)\n",
    "        results['Min HR (beats/min)'] = np.min(hr)\n",
    "        results['Max HR (beats/min)'] = np.max(hr)\n",
    "        # results['NN50'] = np.sum(np.abs(np.diff(rr)) > 50) * 1\n",
    "        # results['pNN50 (%)'] = 100 * np.sum((np.abs(np.diff(rr)) > 50) * 1) / len(rr)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d61843-9b82-4a27-8e44-523c9af60816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AbsolutePower(signal, fs, low, high):\n",
    "    \"\"\"Calculate absolute power in a specific frequency band.\"\"\"\n",
    "    f, Pxx = welch(signal, fs, nperseg=256)\n",
    "    band_power = np.trapz(Pxx[(f >= low) & (f <= high)], f[(f >= low) & (f <= high)])\n",
    "    return band_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87327ae9-f4f7-40f9-b200-e72f43ce54c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RelativePower(signal, fs, low, high):\n",
    "    \"\"\"Calculate relative power in a specific frequency band.\"\"\"\n",
    "    total_power = AbsolutePower(signal, fs, 0, fs / 2)\n",
    "    band_power = AbsolutePower(signal, fs, low, high)\n",
    "    return band_power / total_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38541cbc-ef9f-4e9a-b8ab-a5024370a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_uco_windows_ecg(ecg_data, fs, start_time, uco_start_time, uco_end_time, additional_file_before=None, additional_start_time_before=None, additional_file_after=None, additional_start_time_after=None, window_len_sec=15):\n",
    "    \"\"\"\n",
    "    Capture UCO time before and after windows and compute ECG features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ecg_data : array-like\n",
    "        The ECG signal data.\n",
    "    fs : int\n",
    "        Sampling frequency of the ECG data.\n",
    "    start_time : str\n",
    "        Start time of the ECG data in format 'HH:MM:SS:%f %p'.\n",
    "    uco_start_time : str\n",
    "        UCO start time in format 'HH:MM:SS.%f %p'.\n",
    "    uco_end_time : str\n",
    "        UCO end time in format 'HH:MM:SS.%f %p'.\n",
    "    additional_file_before : str, optional\n",
    "        Path to the additional file needed for segments before UCO start time.\n",
    "    additional_start_time_before : str, optional\n",
    "        Start time of the additional file for segments before UCO start time.\n",
    "    additional_file_after : str, optional\n",
    "        Path to the additional file needed for segments after UCO end time.\n",
    "    additional_start_time_after : str, optional\n",
    "        Start time of the additional file for segments after UCO end time.\n",
    "    window_len_sec : int\n",
    "        Length of each window in seconds.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : DataFrame\n",
    "        DataFrame containing computed features for each window.\n",
    "    \"\"\"\n",
    "    # Convert times to datetime objects\n",
    "    start_datetime = datetime.strptime(start_time, '%I:%M:%S:%f %p')\n",
    "    uco_start_datetime = datetime.strptime(uco_start_time, '%I:%M:%S.%f %p')\n",
    "    uco_end_datetime = datetime.strptime(uco_end_time, '%I:%M:%S.%f %p')\n",
    "\n",
    "    # Adjust for UCO times that cross midnight\n",
    "    if uco_start_datetime < start_datetime:\n",
    "        uco_start_datetime += timedelta(days=1)\n",
    "    if uco_end_datetime < uco_start_datetime:\n",
    "        uco_end_datetime += timedelta(days=1)\n",
    "    \n",
    "    # Calculate the difference in seconds between the start time and UCO times\n",
    "    time_diff_start = (uco_start_datetime - start_datetime).total_seconds()\n",
    "    time_diff_end = (uco_end_datetime - start_datetime).total_seconds()\n",
    "    \n",
    "    # Convert the time differences to sample indices\n",
    "    uco_start_samples = int(time_diff_start * fs)\n",
    "    uco_end_samples = int(time_diff_end * fs)\n",
    "    \n",
    "    # Define window length in samples\n",
    "    window_len = window_len_sec * fs\n",
    "    \n",
    "    # Calculate the start and end sample indices for the desired windows\n",
    "    start_sample_before = max(0, uco_start_samples - 75 * 60 * fs)\n",
    "    end_sample_before = uco_start_samples - 60 * 60 * fs\n",
    "    start_sample_uco = uco_start_samples\n",
    "    end_sample_uco = uco_end_samples\n",
    "    start_sample_after = uco_end_samples\n",
    "    end_sample_after = min(len(ecg_data), uco_end_samples + 60 * window_len)\n",
    "\n",
    "    print(f\"time diff start: {time_diff_start}\")\n",
    "    print(f\"time diff end: {time_diff_end}\")\n",
    "    print(f\"start sample before UCO: {start_sample_before}\")\n",
    "    print(f\"end sample before UCO: {end_sample_before}\")\n",
    "    print(f\"start sample after UCO: {start_sample_after}\")\n",
    "    print(f\"end sample after UCO: {end_sample_after}\")\n",
    "\n",
    "    data = {\n",
    "        'time': [],\n",
    "        'sdrr': [],\n",
    "        'rmssd': [],\n",
    "        'mrr': [],\n",
    "        'mean_hr': [],\n",
    "        'std_hr': [],\n",
    "        'min_hr': [],\n",
    "        'max_hr': [],\n",
    "        'label': []\n",
    "    }\n",
    "\n",
    "    def process_windows(signal_data, start_sample, end_sample, label):\n",
    "        for start in range(start_sample, end_sample, window_len):\n",
    "            end = start + window_len\n",
    "            if end > len(signal_data):\n",
    "                break  # Ensure the last window doesn't exceed the data length\n",
    "    \n",
    "            segment = signal_data[start:end]\n",
    "            rr_peaks, _ = find_peaks(segment)\n",
    "            rr_intervals = np.diff(rr_peaks)\n",
    "            rr_intervals[np.abs(zscore(rr_intervals)) > 2] = np.median(rr_intervals)\n",
    "    \n",
    "            if len(rr_intervals) == 0:\n",
    "                print(f\"No peaks detected in segment starting at {start / fs} seconds.\")\n",
    "                continue  # Skip this segment if no peaks are detected\n",
    "    \n",
    "            hrv_metrics = timedomain(rr_intervals)\n",
    "    \n",
    "            # Append data to the dictionary\n",
    "            data['time'].append(start / fs)\n",
    "            data['sdrr'].append(hrv_metrics['STD RR/SDNN (ms)'])\n",
    "            data['rmssd'].append(hrv_metrics['RMSSD (ms)'])\n",
    "            data['mrr'].append(hrv_metrics['Mean RR (ms)'])\n",
    "            data['mean_hr'].append(hrv_metrics['Mean HR (beats/min)'])\n",
    "            data['std_hr'].append(hrv_metrics['STD HR (beats/min)'])\n",
    "            data['min_hr'].append(hrv_metrics['Min HR (beats/min)'])\n",
    "            data['max_hr'].append(hrv_metrics['Max HR (beats/min)'])\n",
    "            # data['nn50'].append(hrv_metrics['NN50'])\n",
    "            # data['pnn50'].append(hrv_metrics['pNN50 (%)'])\n",
    "            # data['absolute_power_low'].append(absolute_power_low)\n",
    "            # data['absolute_power_high'].append(absolute_power_high)\n",
    "            # data['relative_power_low'].append(relative_power_low)\n",
    "            # data['relative_power_high'].append(relative_power_high)\n",
    "            data['label'].append(label)\n",
    "    \n",
    "            plt.close()\n",
    "\n",
    "\n",
    "    # Process windows 1 hour and 15 minutes to 1 hour before UCO start time and label as -1\n",
    "    if start_sample_before < end_sample_before:\n",
    "        process_windows(ecg_data, start_sample_before, end_sample_before, label=-1)\n",
    "    elif additional_file_before and additional_start_time_before:\n",
    "        additional_data = loadmat(additional_file_before)['save_data'].flatten()\n",
    "        new_start_datetime_before = datetime.strptime(additional_start_time_before, '%I:%M:%S:%f %p')\n",
    "        \n",
    "        # Adjust for additional start time crossing midnight\n",
    "        if uco_start_datetime < new_start_datetime_before:\n",
    "            uco_start_datetime += timedelta(days=1)\n",
    "        \n",
    "        additional_time_diff_start = (uco_start_datetime - new_start_datetime_before).total_seconds() - 75 * 60\n",
    "        additional_start_samples = int(additional_time_diff_start * fs)\n",
    "        process_windows(additional_data, additional_start_samples, additional_start_samples + 60 * window_len, label=-1)\n",
    "    \n",
    "    # Process windows during UCO and label as 0\n",
    "    process_windows(ecg_data, start_sample_uco, end_sample_uco, label=0)\n",
    "    \n",
    "    # Process windows after UCO end time and label as 1\n",
    "    remaining_duration = len(ecg_data) - start_sample_after\n",
    "    if remaining_duration >= 15 * 60 * fs:\n",
    "        process_windows(ecg_data, start_sample_after, end_sample_after, label=1)\n",
    "    else:\n",
    "        process_windows(ecg_data, start_sample_after, len(ecg_data), label=1)\n",
    "        if additional_file_after and additional_start_time_after:\n",
    "            additional_data = loadmat(additional_file_after)['save_data'].flatten()\n",
    "            new_start_datetime_after = datetime.strptime(additional_start_time_after, '%I:%M:%S:%f %p')\n",
    "            \n",
    "            # Adjust for additional start time crossing midnight\n",
    "            if new_start_datetime_after < start_datetime:\n",
    "                new_start_datetime_after += timedelta(days=1)\n",
    "            \n",
    "            additional_start_samples = 0  # Start from the beginning of the additional file\n",
    "            additional_end_samples = int((15 * 60 * fs - remaining_duration))\n",
    "            process_windows(additional_data, additional_start_samples, additional_end_samples, label=1)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1926bce4-101c-4a44-9686-633be840858f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time diff start: 1757.855758\n",
      "time diff end: 2655.355758\n",
      "start sample before UCO: 0\n",
      "end sample before UCO: -736858\n",
      "start sample after UCO: 1062142\n",
      "end sample after UCO: 1422142\n",
      "Processing completed! All processed files have been saved.\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters\n",
    "main_file = r'D:\\IEEE Sensor\\IEEE Sensor Matlab Data\\ECG\\21044\\Clean Data ECGCUsersvhor0002DownloadsCODE BACK UP-20240215T015228Z-001CODE BACK UPRaw Data2104421044_1-06-2021 9_25_16.2 AM_ UCO file Channel 2.mat'\n",
    "handled_folder_path = r'D:\\IEEE Sensor\\IEEE Sensor Xlsx Data\\ECG_handled'\n",
    "fs = 400  # Sampling frequency\n",
    "start_time = '09:25:16:2 AM'  # Start time of the data\n",
    "uco_start_time = '09:54:34.055758 AM'  # UCO start time\n",
    "uco_end_time = '10:09:31.555758 AM'  # UCO end time\n",
    "\n",
    "additional_file_before = r'D:\\IEEE Sensor\\IEEE Sensor Matlab Data\\ECG\\21044\\Clean Data ECGCUsersvhor0002DownloadsCODE BACK UP-20240215T015228Z-001CODE BACK UPRaw Data2104421044_1-06-2021 9_25_16.2 AM_ UCO file Channel 1.mat'  # Path to additional file for before UCO\n",
    "additional_start_time_before = '11:52:09:0 PM'  # Start time of the additional file for before UCO\n",
    "additional_file_after = r'D:\\IEEE Sensor\\IEEE Sensor Matlab Data\\ECG\\21126\\t'  # Path to additional file for after UCO\n",
    "additional_start_time_after = '09:05:07:3 AM' # Start time of the additional file for after UCO\n",
    "\n",
    "# Make sure the processed folder exists\n",
    "if not os.path.exists(handled_folder_path):\n",
    "    os.makedirs(handled_folder_path)\n",
    "\n",
    "# Load the main file\n",
    "main_data = loadmat(main_file)\n",
    "ecg_data = main_data['save_data'].flatten()\n",
    "\n",
    "# Capture UCO windows and compute features\n",
    "df = capture_uco_windows_ecg(ecg_data, fs, start_time, uco_start_time, uco_end_time, additional_file_before, additional_start_time_before, additional_file_after, additional_start_time_after)\n",
    "\n",
    "# Define new save path\n",
    "folder_name = os.path.basename(os.path.dirname(main_file))\n",
    "new_save_folder = os.path.join(handled_folder_path, folder_name + '_handled')\n",
    "if not os.path.exists(new_save_folder):\n",
    "    os.makedirs(new_save_folder)\n",
    "\n",
    "excel_file_name = os.path.basename(main_file)[:-4] + '.xlsx'  # Change the extension to .xlsx\n",
    "new_excel_file_path = os.path.join(new_save_folder, excel_file_name)\n",
    "\n",
    "df.to_excel(new_excel_file_path, index=False)\n",
    "\n",
    "print(\"Processing completed! All processed files have been saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
