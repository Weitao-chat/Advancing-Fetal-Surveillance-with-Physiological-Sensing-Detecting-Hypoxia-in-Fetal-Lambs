{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8179b1-d806-431f-a999-da424a31eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import welch, find_peaks\n",
    "from scipy.integrate import trapz\n",
    "from scipy.stats import zscore\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f364f959-a9d0-4993-a3d2-95f0f5f3c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fetal_emg_features(emg_signal, fs, new_filename, window_len, overlap=0):\n",
    "    # Rectify the EMG signal\n",
    "    rectified_emg = np.abs(emg_signal)\n",
    "\n",
    "    # Extract amplitude features\n",
    "    features = {\n",
    "        'time': new_filename,\n",
    "        'amplitude_mean': np.mean(rectified_emg),\n",
    "        'amplitude_median': np.median(rectified_emg),\n",
    "        'amplitude_rms': np.sqrt(np.mean(rectified_emg**2)),\n",
    "        'amplitude_std': np.std(rectified_emg),\n",
    "        'amplitude_max': np.max(rectified_emg)\n",
    "    }\n",
    "\n",
    "    # Estimate the PSD using Welch's method\n",
    "    freqs, psd = welch(rectified_emg, fs, nperseg=window_len, noverlap=overlap)\n",
    "\n",
    "    # Extract frequency band powers\n",
    "    features['low_power'] = trapz(psd[(freqs >= 25) & (freqs <= 60)])\n",
    "    features['med_power'] = trapz(psd[(freqs >= 60) & (freqs <= 250)])\n",
    "    features['high_power'] = trapz(psd[(freqs >= 250) & (freqs <= 500)])\n",
    "\n",
    "    # Calculate relative powers\n",
    "    total_power = trapz(psd, freqs)\n",
    "    features['low_rel_power'] = features['low_power'] / total_power\n",
    "    features['mid_rel_power'] = features['med_power'] / total_power\n",
    "    features['high_rel_power'] = features['high_power'] / total_power\n",
    "\n",
    "    # Extract dominant frequency\n",
    "    frequencies = np.fft.fft(emg_signal)\n",
    "    frequency_range = np.fft.fftfreq(len(emg_signal), 1/fs)\n",
    "    dominant_frequency_index = np.argmax(np.abs(frequencies[:len(emg_signal)//2+1]))\n",
    "    features['dominant_frequency'] = np.abs(frequency_range[dominant_frequency_index])\n",
    "\n",
    "    # Extract timing features\n",
    "    threshold = 0.1 * np.max(rectified_emg)\n",
    "    onset_times, offset_times = find_emg_onset_offset(rectified_emg, threshold, fs)\n",
    "    features['duration'] = np.median(np.diff(offset_times))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a35cab-fb27-41a2-bc6d-28ebf1afe98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_emg_onset_offset(emg_signal, threshold, fs):\n",
    "    # Find onset times\n",
    "    above_threshold = emg_signal > threshold\n",
    "    diff_above_threshold = np.diff(above_threshold.astype(int))\n",
    "    onset_times = np.where(diff_above_threshold > 0)[0] + 1\n",
    "\n",
    "    # Find offset times\n",
    "    offset_times = np.where(diff_above_threshold < 0)[0] + 1\n",
    "\n",
    "    # Remove offset times before the first onset time\n",
    "    offset_times = offset_times[offset_times >= onset_times[0]]\n",
    "\n",
    "    # If there are more onset times than offset times, remove the last onset time\n",
    "    if len(onset_times) > len(offset_times):\n",
    "        onset_times = onset_times[:-1]\n",
    "\n",
    "    # Convert onset and offset times from samples to seconds\n",
    "    onset_times = onset_times / fs\n",
    "    offset_times = offset_times / fs\n",
    "\n",
    "    return onset_times, offset_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c43714c-4705-4dc6-ab5d-3912e112481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_uco_windows_emg(emg_data, fs, start_time, uco_start_time, uco_end_time, window_len_sec=15):\n",
    "    \"\"\"\n",
    "    Capture UCO time before and after windows and compute EMG features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    emg_data : array-like\n",
    "        The EMG signal data.\n",
    "    fs : int\n",
    "        Sampling frequency of the EMG data.\n",
    "    start_time : str\n",
    "        Start time of the EMG data in format 'HH:MM:SS:%f %p'.\n",
    "    uco_start_time : str\n",
    "        UCO start time in format 'HH:MM:SS.%f %p'.\n",
    "    uco_end_time : str\n",
    "        UCO end time in format 'HH:MM:SS.%f %p'.\n",
    "    window_len_sec : int\n",
    "        Length of each window in seconds.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : DataFrame\n",
    "        DataFrame containing computed features for each window.\n",
    "    \"\"\"\n",
    "    # Convert times to datetime objects\n",
    "    start_datetime = datetime.strptime(start_time, '%I:%M:%S:%f %p')\n",
    "    uco_start_datetime = datetime.strptime(uco_start_time, '%I:%M:%S.%f %p')\n",
    "    uco_end_datetime = datetime.strptime(uco_end_time, '%I:%M:%S.%f %p')\n",
    "\n",
    "    # Adjust for UCO times that cross midnight\n",
    "    if uco_start_datetime < start_datetime:\n",
    "        uco_start_datetime += timedelta(days=1)\n",
    "    if uco_end_datetime < uco_start_datetime:\n",
    "        uco_end_datetime += timedelta(days=1)\n",
    "\n",
    "    # Calculate the difference in seconds between the start time and UCO times\n",
    "    time_diff_start = (uco_start_datetime - start_datetime).total_seconds()\n",
    "    time_diff_end = (uco_end_datetime - start_datetime).total_seconds()\n",
    "\n",
    "    # Convert the time differences to sample indices\n",
    "    uco_start_samples = int(time_diff_start * fs)\n",
    "    uco_end_samples = int(time_diff_end * fs)\n",
    "\n",
    "    # Define window length in samples\n",
    "    window_len = window_len_sec * fs\n",
    "\n",
    "    # Calculate the start and end sample indices for the desired windows\n",
    "    start_sample_before = max(0, uco_start_samples - 75 * 60 * fs)\n",
    "    end_sample_before = uco_start_samples - 60 * 60 * fs\n",
    "    start_sample_uco = uco_start_samples\n",
    "    end_sample_uco = uco_end_samples\n",
    "    start_sample_after = uco_end_samples\n",
    "    end_sample_after = min(len(emg_data), uco_end_samples + 60 * window_len)\n",
    "\n",
    "    print(f\"time diff start: {time_diff_start}\")\n",
    "    print(f\"time diff end: {time_diff_end}\")\n",
    "    print(f\"start sample before UCO: {start_sample_before}\")\n",
    "    print(f\"end sample before UCO: {end_sample_before}\")\n",
    "    print(f\"start sample after UCO: {start_sample_after}\")\n",
    "    print(f\"end sample after UCO: {end_sample_after}\")\n",
    "\n",
    "    data = {\n",
    "        'time': [],\n",
    "        'amplitude_mean': [],\n",
    "        'amplitude_median': [],\n",
    "        'amplitude_rms': [],\n",
    "        'amplitude_std': [],\n",
    "        'amplitude_max': [],\n",
    "        'low_power': [],\n",
    "        'med_power': [],\n",
    "        'high_power': [],\n",
    "        'low_rel_power': [],\n",
    "        'mid_rel_power': [],\n",
    "        'high_rel_power': [],\n",
    "        'dominant_frequency': [],\n",
    "        'duration': [],\n",
    "        'label': []\n",
    "    }\n",
    "\n",
    "    def process_windows(start_sample, end_sample, label):\n",
    "        for start in range(start_sample, end_sample, window_len):\n",
    "            end = start + window_len\n",
    "            if end > len(emg_data):\n",
    "                break  # Ensure the last window doesn't exceed the data length\n",
    "\n",
    "            segment = emg_data[start:end].flatten()\n",
    "\n",
    "            try:\n",
    "                features = extract_fetal_emg_features(segment, fs, start / fs, window_len, 0)\n",
    "\n",
    "                data['time'].append(start / fs)\n",
    "                data['amplitude_mean'].append(features['amplitude_mean'])\n",
    "                data['amplitude_median'].append(features['amplitude_median'])\n",
    "                data['amplitude_rms'].append(features['amplitude_rms'])\n",
    "                data['amplitude_std'].append(features['amplitude_std'])\n",
    "                data['amplitude_max'].append(features['amplitude_max'])\n",
    "                data['low_power'].append(features['low_power'])\n",
    "                data['med_power'].append(features['med_power'])\n",
    "                data['high_power'].append(features['high_power'])\n",
    "                data['low_rel_power'].append(features['low_rel_power'])\n",
    "                data['mid_rel_power'].append(features['mid_rel_power'])\n",
    "                data['high_rel_power'].append(features['high_rel_power'])\n",
    "                data['dominant_frequency'].append(features['dominant_frequency'])\n",
    "                data['duration'].append(features['duration'])\n",
    "                data['label'].append(label)\n",
    "\n",
    "                plt.close()\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing segment: {e}\")\n",
    "\n",
    "    # Process windows 1 hour and 15 minutes to 1 hour before UCO start time and label as -1\n",
    "    process_windows(start_sample_before, end_sample_before, label=-1)\n",
    "\n",
    "    # Process windows during UCO and label as 0\n",
    "    process_windows(start_sample_uco, end_sample_uco, label=0)\n",
    "\n",
    "    # Process windows after UCO end time and label as 1\n",
    "    process_windows(start_sample_after, end_sample_after, label=1)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a97a4b2-028d-4881-b959-aa9822c3b1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time diff start: 60.469337\n",
      "time diff end: 120.469337\n",
      "start sample before UCO: 0\n",
      "end sample before UCO: -7079062\n",
      "start sample after UCO: 240938\n",
      "end sample after UCO: 253700\n",
      "time diff start: 60.469337\n",
      "time diff end: 120.469337\n",
      "start sample before UCO: 0\n",
      "end sample before UCO: -7079062\n",
      "start sample after UCO: 240938\n",
      "end sample after UCO: 240400\n",
      "Processing completed! All processed files have been saved.\n"
     ]
    }
   ],
   "source": [
    "# THIS BLOCK OF CODE REQUIRES REAL DATA\n",
    "\n",
    "# Define the parameters\n",
    "folder_path = r'Matlab code for preprocessing\\Fake data\\21203'\n",
    "handled_folder_path = r'result\\EMG_handled'\n",
    "fs = 2000  # Sampling frequency\n",
    "start_time = '09:40:26:003 AM'  # Start time of the data\n",
    "uco_start_time = '09:41:26.472337 AM'  # UCO start time\n",
    "uco_end_time = '09:42:26.472337 AM'  # UCO end time\n",
    "\n",
    "# Make sure the processed folder exists\n",
    "if not os.path.exists(handled_folder_path):\n",
    "    os.makedirs(handled_folder_path)\n",
    "\n",
    "# Only process files in the specific folder\n",
    "folder_path_current = os.path.join(folder_path)\n",
    "mat_files = [file for file in os.listdir(folder_path_current) if file.endswith('_EMG.mat')]\n",
    "\n",
    "for mat_file in mat_files:\n",
    "    file_path_1 = os.path.join(folder_path_current, mat_file)\n",
    "    mat_contents = loadmat(file_path_1)\n",
    "    emg_data = mat_contents['save_data'].flatten()\n",
    "\n",
    "    # Capture UCO windows and compute features\n",
    "    df = capture_uco_windows_emg(emg_data, fs, start_time, uco_start_time, uco_end_time)\n",
    "\n",
    "    # Define new save path\n",
    "    folder_name = os.path.basename(folder_path)\n",
    "    new_save_folder = os.path.join(handled_folder_path, folder_name + '_handled')\n",
    "    if not os.path.exists(new_save_folder):\n",
    "        os.makedirs(new_save_folder)\n",
    "\n",
    "    excel_file_name = mat_file[:-4] + '.xlsx'  # Change the extension to .xlsx\n",
    "    new_excel_file_path = os.path.join(new_save_folder, excel_file_name)\n",
    "\n",
    "    df.to_excel(new_excel_file_path, index=False)\n",
    "\n",
    "print(\"Processing completed! All processed files have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262877a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
